{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple walkthrough of how the code works.\n",
    "\n",
    "First, we look at the main components of the pipeline, the `context_shortener` and the `form_filler`\n",
    "The `context_shortener` is responsible for the retrieval part (reducing the length of the context, from the full document to the chunks.)\n",
    "The `form_filler` takes the context and a form, and fills it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## context shortening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondre/miniconda3/envs/upcast/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import context_shortening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we chunk some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Melanoma is the most dangerous type of skin\n",
      "1 : cancer; it develops from the melanin-producing\n",
      "2 : cells known as melanocytes.[1] It typically\n",
      "3 : occurs in the skin, but may rarely occur in the\n",
      "4 : mouth, intestines, or eye (uveal melanoma).[1][2]\n"
     ]
    }
   ],
   "source": [
    "# some sample text from wikipedia\n",
    "document = \"\"\"Melanoma is the most dangerous type of skin cancer; it develops from the melanin-producing cells known as melanocytes.[1] It typically occurs in the skin, but may rarely occur in the mouth, intestines, or eye (uveal melanoma).[1][2]\"\"\"\n",
    "chunks = context_shortening.chunk_by_headeres_and_clean(document, 50, 0, False)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(i,\":\",chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a pydantic model in order for the context_shortener to know what to look for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "from typing import Literal\n",
    "class Disease(pydantic.BaseModel):\n",
    "\n",
    "    Disease_name: str = pydantic.Field(description=\"Name of disease\")\n",
    "    Body_part: Literal[\"Leg\", \"Arm\", \"Skin\"] = pydantic.Field(description=\"Affected body part\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try out some context shorteners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouth, intestines, or eye (uveal melanoma).[1][2]\n",
      "...\n",
      "occurs in the skin, but may rarely occur in the\n",
      "...\n",
      "Melanoma is the most dangerous type of skin\n"
     ]
    }
   ],
   "source": [
    "description_based_retriever = context_shortening.Retrieval(\n",
    "    chunk_info_to_compare=\"direct\", # this means we use the chunk directly, as opposed to \"keybert\" which generates n keywords per chunk.\n",
    "    field_info_to_compare=\"description\",\n",
    "    include_choice_every=1,\n",
    "    embedding_model_id=\"all-MiniLM-L6-v2\",\n",
    "    n_keywords=1,\n",
    "    top_k=3, # find k most relevant chunks, and put into one string\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=0,\n",
    "    pydantic_form=Disease,\n",
    ")\n",
    "description_based_retriever.set_document(document)\n",
    "disease_name_context = description_based_retriever(answer_field_name = \"Disease_name\")\n",
    "print(disease_name_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occurs in the skin, but may rarely occur in the\n",
      "...\n",
      "mouth, intestines, or eye (uveal melanoma).[1][2]\n",
      "...\n",
      "Melanoma is the most dangerous type of skin\n"
     ]
    }
   ],
   "source": [
    "body_part_context = description_based_retriever(answer_field_name = \"Body_part\")\n",
    "print(body_part_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choices or choise-list alternative require only literal values in the pydantic_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melanoma is the most dangerous type of skin\n",
      "...\n",
      "occurs in the skin, but may rarely occur in the\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "from typing import Literal\n",
    "class LiteralDisease(pydantic.BaseModel):\n",
    "\n",
    "    Disease_name: Literal[\"Carcinoma\", \"'Melanoma'\", \"Medulloblastoma\"] = pydantic.Field(description=\"Name of disease\")\n",
    "    Body_part: Literal[\"Leg\", \"Arm\", \"Skin\"] = pydantic.Field(description=\"Affected body part\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "choices_based_retriever = context_shortening.Retrieval(\n",
    "    chunk_info_to_compare=\"direct\", # this means we use the chunk directly, as opposed to \"keybert\" which generates n keywords per chunk.\n",
    "    field_info_to_compare=\"choices\",\n",
    "    include_choice_every=1,\n",
    "    embedding_model_id=\"all-MiniLM-L6-v2\",\n",
    "    n_keywords=1,\n",
    "    top_k=2,\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=0,\n",
    "    pydantic_form=LiteralDisease,\n",
    ")\n",
    "\n",
    "choices_based_retriever.set_document(document)\n",
    "\n",
    "context = choices_based_retriever(answer_field_name = \"Body_part\")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form Filling\n",
    "\n",
    "\n",
    "First we load an llm - llama3.1 8b instruct, gptq-int4 quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]\n",
      "Some weights of the model checkpoint at hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4 were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
      "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import outlines\n",
    "model_id = \"hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4\"\n",
    "dspy_model = dspy.HFModel(model = model_id, hf_device_map = \"cuda:0\")\n",
    "\n",
    "hf_model = dspy_model.model\n",
    "hf_tokenizer = dspy_model.tokenizer\n",
    "\n",
    "# set some dspy model options\n",
    "#dspy_model.kwargs[\"max_tokens\"]=args.max_tokens\n",
    "dspy_model.drop_prompt_from_output = True\n",
    "\n",
    "# define outlines llm and sampler\n",
    "outlines_llm = outlines.models.Transformers(model=hf_model, tokenizer=hf_tokenizer)\n",
    "outlines_sampler = outlines.samplers.GreedySampler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import form_filling\n",
    "\n",
    "form_filler = form_filling.SequentialFormFiller(\n",
    "    outlines_llm=outlines_llm,\n",
    "    outlines_sampler=outlines_sampler,\n",
    "    pydantic_form=Disease,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease_name='Malignant melanoma' Body_part='Skin'\n"
     ]
    }
   ],
   "source": [
    "filled_form = form_filler.forward(description_based_retriever)\n",
    "\n",
    "print(filled_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Disease_name is str (not literal) so its evaluated with similarity.\n",
    "Body_part is Literal, so 1 if its correct else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Disease_name': 0.8594872219577656, 'Body_part': 1.0}\n"
     ]
    }
   ],
   "source": [
    "labels = {\"Disease_name\":[\"melanoma\"], \"Body_part\":[\"Skin\"]}\n",
    "\n",
    "import evaluation\n",
    "scores = evaluation.score_general_prediction(labels, filled_form)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare, we make up some other labels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Disease_name': 0.6777031254235824, 'Body_part': 0.0}\n"
     ]
    }
   ],
   "source": [
    "labels = {\"Disease_name\":[\"Cancer\"], \"Body_part\":[\"Leg\"]}\n",
    "\n",
    "import evaluation\n",
    "scores = evaluation.score_general_prediction(labels, filled_form)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_loader\n",
    "documents, labels = dataset_loader.load_arxpr_data(max_amount=6, version=\"2_25\", mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26925227 : BioC-API\n",
      "collection.key\n",
      "CC BY\n",
      "[version 2; referees: 2 approved]\n",
      "RNA-seq quantification gene expression transcriptomics\n",
      "This is an open access article distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\n",
      "surname:Soneson;given-names:Charlotte\n",
      "surname:Love;given-names:Michael I.\n",
      "surname:Robinson;given-names:Mark D.\n",
      "In version 2 of the manuscript, we have re\n",
      "\n",
      "25435910 : BioC-API\n",
      "collection.key\n",
      "CC BY\n",
      "Cellobiose Glycolysis Systems biology Transcription factor Metabolic engineering Biofuels\n",
      "This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/)\n",
      "\n",
      "23671666 : BioC-API\n",
      "collection.key\n",
      "CC BY\n",
      "Hoxa2 Controls Pcp4 Expression\n",
      "This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.\n",
      "surname:Anderson;given-names:Megan\n",
      "surname:Amin;given-names:Shilu\n",
      "surname:Luise;given-names:Fabiana\n",
      "surname:Zeef;given-names:Leo\n",
      "surname:Bobola;given-names:Nicoletta\n",
      "surname:Mallo;given-names:Mo\n",
      "\n",
      "23079210 : BioC-API\n",
      "collection.key\n",
      "CC BY\n",
      "This is an open access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\n",
      "surname:Hardy;given-names:Rowan\n",
      "surname:Juarez;given-names:Maria\n",
      "surname:Naylor;given-names:Amy\n",
      "surname:Tu;given-names:Jinwen\n",
      "surname:Rabbitt;given-names:Elizabeth H\n",
      "surname:Filer;given-names:Andre\n",
      "\n",
      "29980666 : BioC-API\n",
      "collection.key\n",
      "CC BY\n",
      "Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licens\n",
      "\n",
      "21299862 : BioC-API\n",
      "collection.key\n",
      "CC BY\n",
      "This is an open access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\n",
      "surname:Salazar;given-names:Marcela D\n",
      "surname:Ratnam;given-names:Maya\n",
      "surname:Patki;given-names:Mugdha\n",
      "surname:Kisovic;given-names:Ivana\n",
      "surname:Trumbly;given-names:Robert\n",
      "surname:Iman;given-names:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in documents:\n",
    "    print(key,\":\", documents[key][:500])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'26925227': {'hardware_4': ['illumina hiseq 2000'],\n",
       "  'organism_part_5': [],\n",
       "  'experimental_designs_10': ['case control design'],\n",
       "  'assay_by_molecule_14': ['rna assay'],\n",
       "  'study_type_18': ['rna-seq of coding rna']},\n",
       " '25435910': {'hardware_4': [],\n",
       "  'organism_part_5': [],\n",
       "  'experimental_designs_10': [],\n",
       "  'assay_by_molecule_14': ['rna assay'],\n",
       "  'study_type_18': ['rna-seq of coding rna']},\n",
       " '23671666': {'hardware_4': [],\n",
       "  'organism_part_5': [],\n",
       "  'experimental_designs_10': [],\n",
       "  'assay_by_molecule_14': ['rna assay'],\n",
       "  'study_type_18': ['transcription profiling by array']},\n",
       " '23079210': {'hardware_4': [],\n",
       "  'organism_part_5': [],\n",
       "  'experimental_designs_10': [],\n",
       "  'assay_by_molecule_14': [],\n",
       "  'study_type_18': ['transcription profiling by rt-pcr']},\n",
       " '29980666': {'hardware_4': ['illumina hiseq 2000'],\n",
       "  'organism_part_5': [],\n",
       "  'experimental_designs_10': [],\n",
       "  'assay_by_molecule_14': [],\n",
       "  'study_type_18': []},\n",
       " '21299862': {'hardware_4': [],\n",
       "  'organism_part_5': [],\n",
       "  'experimental_designs_10': [],\n",
       "  'assay_by_molecule_14': ['rna assay'],\n",
       "  'study_type_18': ['transcription profiling by array']}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_modules and run_modules\n",
    "\n",
    "\n",
    "For these, just take a look at/run ´main.py´.\n",
    "load_modules loads a set of documents/labels, as well as a context_shortener and form_filler, as specified in the arguments.\n",
    "run_modules iterates through these and evaluate each time, and stores the scores in wandb/weave (requires login details - create your own wandb project if you want to use this)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
